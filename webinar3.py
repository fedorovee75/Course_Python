#Classifier image (10 class, image 28x28)
#Create Autoencoder (first variant)
import numpy, tensorflow, matplotlib.pyplot
(x_train, _), (x_test, _) = tensorflow.keras.datasets.mnist.load_data()
#x_train.shape=(60000, 28, 28), x_test.shape=(60000, 28, 28)
#y_train.shape=(60000,), y_test.shape=(10000,)
x_train = x_train.reshape(60000, 784).astype("float32") / 255
#x_train.shape=(60000, 784)
x_test = x_test.reshape(10000, 784).astype("float32") / 255
#x_test.shape=(10000, 784)
inputs = tensorflow.keras.Input(shape=(784,))
hidden1 = tensorflow.keras.layers.Dense(units=64, activation='relu')(inputs)
hidden2 = tensorflow.keras.layers.Dense(units=32, activation='relu')(hidden1)
hidden3 = tensorflow.keras.layers.Dense(units=64, activation='relu')(hidden2)
outputs = tensorflow.keras.layers.Dense(units=784, activation='sigmoid')(hidden3)
autoencoder = tensorflow.keras.Model(inputs=inputs, outputs=outputs, name="mnist_model")
autoencoder.compile(loss='binary_crossentropy', optimizer="RMSprop", metrics=["accuracy"])
autoencoder.fit(x=x_train, y=x_train, epochs=2, batch_size=64, validation_split=0.2)
test_scores = autoencoder.evaluate(x=x_test, y=x_test, verbose=2)
print("Test loss:", test_scores[0])
print("Test accuracy:", test_scores[1])
y_model = autoencoder.predict(x=x_test)
fig = matplotlib.pyplot.figure()
ax_1 = fig.add_subplot(1, 2, 1)
ax_2 = fig.add_subplot(1, 2, 2)
ax_1.imshow(x_test[1].reshape(28, 28)*255)
ax_1.axis('off')
ax_2.imshow(y_model[1].reshape(28, 28)*255)
ax_2.axis('off')
matplotlib.pyplot.show()
autoencoder.summary()
tensorflow.keras.utils.plot_model(autoencoder, show_shapes=True)

#Classifier image (10 class, image 28x28)
#Create Autoencoder (second variant)
import numpy, tensorflow, matplotlib.pyplot
(x_train, _), (x_test, _) = tensorflow.keras.datasets.mnist.load_data()
#x_train.shape=(60000, 28, 28), x_test.shape=(60000, 28, 28)
x_train = x_train.reshape(60000, 784).astype("float32") / 255
#x_train.shape=(60000, 784)
x_test = x_test.reshape(10000, 784).astype("float32") / 255
#x_test.shape=(10000, 784)
autoencoder = tensorflow.keras.models.Sequential()
autoencoder.add(tensorflow.keras.layers.Dense(units=64, input_shape=(784,), activation="relu"))
autoencoder.add(tensorflow.keras.layers.Dense(units=32, activation='relu'))
autoencoder.add(tensorflow.keras.layers.Dense(units=64, activation='relu'))
autoencoder.add(tensorflow.keras.layers.Dense(units=784, activation='sigmoid'))
autoencoder.compile(loss='binary_crossentropy', optimizer="RMSprop", metrics=["accuracy"])
autoencoder.fit(x=x_train, y=x_train, epochs=2, batch_size=64, validation_split=0.2)
test_scores = autoencoder.evaluate(x=x_test, y=x_test, verbose=2)
print("Test loss:", test_scores[0])
print("Test accuracy:", test_scores[1])
y_model = autoencoder.predict(x=x_test)
fig = matplotlib.pyplot.figure()
ax_1 = fig.add_subplot(1, 2, 1)
ax_2 = fig.add_subplot(1, 2, 2)
ax_1.imshow(x_test[1].reshape(28, 28)*255)
ax_1.axis('off')
ax_2.imshow(y_model[1].reshape(28, 28)*255)
ax_2.axis('off')
matplotlib.pyplot.show()
autoencoder.summary()
tensorflow.keras.utils.plot_model(autoencoder, show_shapes=True)

#Classifier image (10 class, image 28x28)
#Create SRN (first variant)
import numpy, tensorflow
(x_train, y_train), (x_test, y_test) = tensorflow.keras.datasets.mnist.load_data()
#x_train.shape=(60000, 28, 28), x_test.shape=(60000, 28, 28)
x_train = x_train.reshape(60000, 1, 784).astype("float32") / 255
#x_train.shape=(60000, 1, 784)
x_test = x_test.reshape(10000, 1, 784).astype("float32") / 255
#x_test.shape=(10000, 1, 784)
y_train = tensorflow.keras.utils.to_categorical(y_train)
#y_train.shape=(60000, 10)
y_test = tensorflow.keras.utils.to_categorical(y_test)
#y_test.shape=(60000, 10)
inputs = tensorflow.keras.Input(shape=(1,784))
hidden = tensorflow.keras.layers.SimpleRNN(units=64)(inputs)
outputs = tensorflow.keras.layers.Dense(units=10, activation='softmax')(hidden)
srn = tensorflow.keras.Model(inputs=inputs, outputs=outputs, name="mnist_model")
srn.compile(optimizer="RMSprop", loss='categorical_crossentropy', metrics=["accuracy"])
history = srn.fit(x=x_train, y=y_train, batch_size=64, epochs=2, validation_split=0.2)
test_scores = srn.evaluate(x=x_test, y=y_test, verbose=2)
print("Test loss:", test_scores[0])
print("Test accuracy:", test_scores[1])
y_model = srn.predict(x=x_test)
print("y_test[1:10]:", numpy.argmax(y_test[1:10], axis=1))
print("y_model[1:10]:", numpy.argmax(y_model[1:10], axis=1))
srn.summary()
tensorflow.keras.utils.plot_model(srn, show_shapes=True)

#Classifier image (10 class, image 28x28)
#Create SRN (second variant)
import numpy, tensorflow
(x_train, y_train), (x_test, y_test) = tensorflow.keras.datasets.mnist.load_data()
#x_train.shape=(60000, 28, 28), x_test.shape=(60000, 28, 28)
#y_train.shape=(60000,), y_test.shape=(10000,)
x_train = x_train.reshape(60000, 1, 784).astype("float32") / 255
#x_train.shape=(60000, 1, 784)
x_test = x_test.reshape(10000, 1, 784).astype("float32") / 255
#x_test.shape=(10000, 1, 784)
y_train = tensorflow.keras.utils.to_categorical(y_train)
#y_train.shape=(60000, 10)
y_test = tensorflow.keras.utils.to_categorical(y_test)
#y_test.shape=(60000, 10)
srn = tensorflow.keras.models.Sequential()
srn.add(tensorflow.keras.layers.SimpleRNN(units=64, input_shape=(1,784)))
srn.add(tensorflow.keras.layers.Dense(units=10, activation='softmax')) 
srn.compile(optimizer="RMSprop", loss='categorical_crossentropy', metrics=["accuracy"])
history = srn.fit(x=x_train, y=y_train, batch_size=64, epochs=2, validation_split=0.2)
test_scores = srn.evaluate(x=x_test, y=y_test, verbose=2)
print("Test loss:", test_scores[0])
print("Test accuracy:", test_scores[1])
y_model = srn.predict_classes(x=x_test)
print("y_test[1:10]:", numpy.argmax(y_test[1:10], axis=1))
print("y_model[1:10]:", y_model[1:10])
srn.summary()
tensorflow.keras.utils.plot_model(srn, show_shapes=True)

#Approximation
#Create SRN (first variant)
import numpy, sklearn.model_selection, tensorflow, matplotlib.pyplot
step = 4      
t = numpy.arange(0,1000+step)
data = numpy.sin(0.02*t)+2*numpy.random.rand(1000+step)
X, Y =[], []
for i in range(len(data)-step):
    X.append(data[i:i+step])
    Y.append(data[i+step])
(x_train, x_test, y_train, y_test) = sklearn.model_selection.train_test_split(
    numpy.array(X), numpy.array(Y), test_size=200)
#x_train.shape=(800, 4), x_test.shape=(200, 4)
#y_train.shape=(800,), y_test.shape=(200,)
x_train = x_train.reshape(800, step, 1)
#x_train.shape=(800, 4, 1)
x_test = x_test.reshape(200, step, 1)
#x_test.shape=(200, 4, 1)
inputs = tensorflow.keras.Input(shape=(step, 1))
hidden = tensorflow.keras.layers.SimpleRNN(units=32)(inputs)
outputs = tensorflow.keras.layers.Dense(units=1)(hidden)
srn = tensorflow.keras.Model(inputs=inputs, outputs=outputs, name="mnist_model")
srn.compile(optimizer="RMSprop", loss='mean_squared_error')
history = srn.fit(x=x_train, y=y_train, batch_size=16, epochs=2, validation_split=0.2)
test_scores = srn.evaluate(x=x_test, y=y_test, verbose=2)
print("Test loss:", test_scores)
y_model = srn.predict(x=x_test)
print("y_test[1:10]:", y_test[1:10])
print("y_model[1:10]:", y_model[1:10].reshape(9))
fig = matplotlib.pyplot.figure()
ax = fig.add_subplot(1, 1, 1)
ax.plot(y_test)
ax.plot(y_model)
x=numpy.arange(0,200)
matplotlib.pyplot.plot(x, y_test, label ="y_test", color='b')
matplotlib.pyplot.plot(x, y_model, label = "y_model", color='r')
matplotlib.pyplot.legend()
matplotlib.pyplot.show()
srn.summary()
tensorflow.keras.utils.plot_model(srn, show_shapes=True)

#Approximation
#Create SRN (second variant)
import numpy, sklearn.model_selection, tensorflow, matplotlib.pyplot
step = 4      
t = numpy.arange(0,1000+step)
data = numpy.sin(0.02*t)+2*numpy.random.rand(1000+step)
X, Y =[], []
for i in range(len(data)-step):
    X.append(data[i:i+step])
    Y.append(data[i+step])
(x_train, x_test, y_train, y_test) = sklearn.model_selection.train_test_split(
    numpy.array(X), numpy.array(Y), test_size=200)
#x_train.shape=(800, 4), x_test.shape=(200, 4)
#y_train.shape=(800,), y_test.shape=(200,)
x_train = x_train.reshape(800, step, 1)
#x_train.shape=(800, 4, 1)
x_test = x_test.reshape(200, step, 1)
#x_test.shape=(200, 4, 1)
srn = tensorflow.keras.models.Sequential()
srn.add(tensorflow.keras.layers.SimpleRNN(units=32, input_shape=(step, 1)))
srn.add(tensorflow.keras.layers.Dense(units=1)) 
srn.compile(optimizer="RMSprop", loss='mean_squared_error')
history = srn.fit(x=x_train, y=y_train, batch_size=16, epochs=2, validation_split=0.2)
test_scores = srn.evaluate(x=x_test, y=y_test, verbose=2)
print("Test loss:", test_scores)
y_model = srn.predict(x=x_test)
print("y_test[1:10]:", y_test[1:10])
print("y_model[1:10]:", y_model[1:10].reshape(9))
fig = matplotlib.pyplot.figure()
ax = fig.add_subplot(1, 1, 1)
ax.plot(y_test)
ax.plot(y_model)
x=numpy.arange(0,200)
matplotlib.pyplot.plot(x, y_test, label ="y_test", color='b')
matplotlib.pyplot.plot(x, y_model, label = "y_model", color='r')
matplotlib.pyplot.legend()
matplotlib.pyplot.show()
srn.summary()
tensorflow.keras.utils.plot_model(srn, show_shapes=True)

#Classifier image (10 class, image 28x28)
#Create BRN (first variant)
import numpy, tensorflow
(x_train, y_train), (x_test, y_test) = tensorflow.keras.datasets.mnist.load_data()
#x_train.shape=(60000, 28, 28), x_test.shape=(60000, 28, 28)
#y_train.shape=(60000,), y_test.shape=(10000,)
x_train = x_train.reshape(60000, 1, 784).astype("float32") / 255
#x_train.shape=(60000, 1, 784)
x_test = x_test.reshape(10000, 1, 784).astype("float32") / 255
#x_test.shape=(10000, 1, 784)
y_train = tensorflow.keras.utils.to_categorical(y_train)
#y_train.shape=(60000, 10)
y_test = tensorflow.keras.utils.to_categorical(y_test)
#y_test.shape=(60000, 10)
inputs = tensorflow.keras.Input(shape=(1, 784))
hidden1 = tensorflow.keras.layers.Bidirectional(
    tensorflow.keras.layers.SimpleRNN(units=64, return_sequences=True))(inputs)
hidden2 = tensorflow.keras.layers.Bidirectional(
    tensorflow.keras.layers.SimpleRNN(units=64))(hidden1)
outputs = tensorflow.keras.layers.Dense(units=10, activation='softmax')(hidden2)
brn = tensorflow.keras.Model(inputs=inputs, outputs=outputs, name="mnist_model")
brn.compile(optimizer="RMSprop", loss='categorical_crossentropy', metrics=["accuracy"])
history = brn.fit(x=x_train, y=y_train, batch_size=64, epochs=2, validation_split=0.2)
test_scores = brn.evaluate(x=x_test, y=y_test, verbose=2)
print("Test loss:", test_scores[0])
print("Test accuracy:", test_scores[1])
y_model = brn.predict(x=x_test)
print("y_test[1:10]:", numpy.argmax(y_test[1:10], axis=1))
print("y_model[1:10]:", numpy.argmax(y_model[1:10], axis=1))
brn.summary()
tensorflow.keras.utils.plot_model(brn, show_shapes=True)

#Classifier image (10 class, image 28x28)
#Create BRN (second variant)
import numpy, tensorflow
(x_train, y_train), (x_test, y_test) = tensorflow.keras.datasets.mnist.load_data()
#x_train.shape=(60000, 28, 28), x_test.shape=(60000, 28, 28)
#y_train.shape=(60000,), y_test.shape=(10000,)
x_train = x_train.reshape(60000, 1, 784).astype("float32") / 255
#x_train.shape=(60000, 1, 784)
x_test = x_test.reshape(10000, 1, 784).astype("float32") / 255
#x_test.shape=(10000, 1, 784)
y_train = tensorflow.keras.utils.to_categorical(y_train)
#y_train.shape=(60000, 10)
y_test = tensorflow.keras.utils.to_categorical(y_test)
#y_test.shape=(60000, 10)
brn = tensorflow.keras.models.Sequential()
brn.add(tensorflow.keras.layers.Bidirectional(
    tensorflow.keras.layers.SimpleRNN(units=64, return_sequences=True, input_shape=(1, 784))))
brn.add(tensorflow.keras.layers.Bidirectional(
    tensorflow.keras.layers.SimpleRNN(units=64)))
brn.add(tensorflow.keras.layers.Dense(units=10, activation='softmax'))
brn.compile(optimizer="RMSprop", loss='categorical_crossentropy', metrics=["accuracy"])
history = brn.fit(x=x_train, y=y_train, batch_size=64, epochs=2, validation_split=0.2)
test_scores = brn.evaluate(x=x_test, y=y_test, verbose=2)
print("Test loss:", test_scores[0])
print("Test accuracy:", test_scores[1])
y_model = brn.predict_classes(x=x_test)
print("y_test[1:10]:", numpy.argmax(y_test[1:10], axis=1))
print("y_model[1:10]:", y_model[1:10])
brn.summary()
tensorflow.keras.utils.plot_model(brn, show_shapes=True)

#Approximation
#Create BRN (first variant)
import numpy, sklearn.model_selection, tensorflow, matplotlib.pyplot
step = 4      
t = numpy.arange(0,1000+step)
data = numpy.sin(0.02*t)+2*numpy.random.rand(1000+step)
X, Y =[], []
for i in range(len(data)-step):
    X.append(data[i:i+step])
    Y.append(data[i+step])
(x_train, x_test, y_train, y_test) = sklearn.model_selection.train_test_split(
    numpy.array(X), numpy.array(Y), test_size=200)
#x_train.shape=(800, 4), x_test.shape=(200, 4)
#y_train.shape=(800,), y_test.shape=(200,)
x_train = x_train.reshape(800, step, 1)
#x_train.shape=(800, 4, 1)
x_test = x_test.reshape(200, step, 1)
#x_test.shape=(200, 4, 1)
inputs = tensorflow.keras.Input(shape=(step, 1))
hidden1 = tensorflow.keras.layers.Bidirectional(
    tensorflow.keras.layers.SimpleRNN(units=32, return_sequences=True))(inputs)
hidden2 = tensorflow.keras.layers.Bidirectional(
    tensorflow.keras.layers.SimpleRNN(units=32))(hidden1)
outputs = tensorflow.keras.layers.Dense(units=1)(hidden2)
brn = tensorflow.keras.Model(inputs=inputs, outputs=outputs, name="mnist_model")
brn.compile(optimizer="RMSprop", loss='mean_squared_error')
history = brn.fit(x=x_train, y=y_train, batch_size=16, epochs=2, validation_split=0.2)
test_scores = brn.evaluate(x=x_test, y=y_test, verbose=2)
print("Test loss:", test_scores)
y_model = brn.predict(x=x_test)
print("y_test[1:10]:", y_test[1:10])
print("y_model[1:10]:", y_model[1:10].reshape(9))
fig = matplotlib.pyplot.figure()
ax = fig.add_subplot(1, 1, 1)
ax.plot(y_test)
ax.plot(y_model)
x=numpy.arange(0,200)
matplotlib.pyplot.plot(x, y_test, label ="y_test", color='b')
matplotlib.pyplot.plot(x, y_model, label = "y_model", color='r')
matplotlib.pyplot.legend()
matplotlib.pyplot.show()
brn.summary()
tensorflow.keras.utils.plot_model(brn, show_shapes=True)

#Approximation
#Create BRN (second variant)
import numpy, sklearn.model_selection, tensorflow, matplotlib.pyplot
step = 4      
t = numpy.arange(0,1000+step)
data = numpy.sin(0.02*t)+2*numpy.random.rand(1000+step)
X, Y =[], []
for i in range(len(data)-step):
    X.append(data[i:i+step])
    Y.append(data[i+step])
(x_train, x_test, y_train, y_test) = sklearn.model_selection.train_test_split(
    numpy.array(X), numpy.array(Y), test_size=200)
#x_train.shape=(800, 4), x_test.shape=(200, 4)
#y_train.shape=(800,), y_test.shape=(200,)
x_train = x_train.reshape(800, step, 1)
#x_train.shape=(800, 4, 1)
x_test = x_test.reshape(200, step, 1)
#x_test.shape=(200, 4, 1)
brn = tensorflow.keras.models.Sequential()
brn.add(tensorflow.keras.layers.Bidirectional(
    tensorflow.keras.layers.SimpleRNN(units=32, return_sequences=True, input_shape=(step, 1))))
brn.add(tensorflow.keras.layers.Bidirectional(
    tensorflow.keras.layers.SimpleRNN(units=32)))
brn.add(tensorflow.keras.layers.Dense(units=1))
brn.compile(optimizer="RMSprop", loss='mean_squared_error')
history = brn.fit(x=x_train, y=y_train, batch_size=16, epochs=2, validation_split=0.2)
test_scores = brn.evaluate(x=x_test, y=y_test, verbose=2)
print("Test loss:", test_scores)
y_model = brn.predict(x=x_test)
print("y_test[1:10]:", y_test[1:10])
print("y_model[1:10]:", y_model[1:10].reshape(9))
fig = matplotlib.pyplot.figure()
ax = fig.add_subplot(1, 1, 1)
ax.plot(y_test)
ax.plot(y_model)
x=numpy.arange(0,200)
matplotlib.pyplot.plot(x, y_test, label ="y_test", color='b')
matplotlib.pyplot.plot(x, y_model, label = "y_model", color='r')
matplotlib.pyplot.legend()
matplotlib.pyplot.show()
brn.summary()
tensorflow.keras.utils.plot_model(brn, show_shapes=True)
