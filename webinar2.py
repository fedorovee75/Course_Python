#Classifier image (10 class, image 28x28)
#Create MLP (first variant)
import numpy, tensorflow
(x_train, y_train), (x_test, y_test) = tensorflow.keras.datasets.mnist.load_data()
#x_train.shape=(60000, 28, 28), x_test.shape=(10000, 28, 28)
#y_train.shape=(60000,), y_test.shape=(10000,)
x_train = x_train.reshape(60000, 784).astype("float32") / 255
#x_train.shape=(60000, 784)
x_test = x_test.reshape(10000, 784).astype("float32") / 255
#x_test.shape=(10000, 784)
y_train = tensorflow.keras.utils.to_categorical(y_train)
#y_train.shape=(60000, 10)
y_test = tensorflow.keras.utils.to_categorical(y_test)
#y_test.shape=(10000, 10)
#5 => (0,0,0,0,1,0,0,0,0,0)
inputs = tensorflow.keras.Input(shape=(784,))
hidden1 = tensorflow.keras.layers.Dense(units=64, activation='relu')(inputs)
hidden2 = tensorflow.keras.layers.Dense(units=64, activation='relu')(hidden1)
outputs = tensorflow.keras.layers.Dense(units=10, activation='softmax')(hidden2)
mlp = tensorflow.keras.Model(inputs=inputs, outputs=outputs, name="mnist_model")
mlp.compile(optimizer="RMSprop", loss='categorical_crossentropy', metrics=["accuracy"])
history = mlp.fit(x=x_train, y=y_train, batch_size=64, epochs=2, validation_split=0.2)
test_scores = mlp.evaluate(x=x_test, y=y_test, verbose=2)
print("Test loss:", test_scores[0])
print("Test accuracy:", test_scores[1])
y_model = mlp.predict(x=x_test)
print("y_test[1:10]:", numpy.argmax(y_test[1:10], axis=1))
print("y_model[1:10]:", numpy.argmax(y_model[1:10], axis=1))
mlp.summary()
tensorflow.keras.utils.plot_model(mlp, show_shapes=True)

#Classifier image (10 class, image 28x28)
#Create MLP (second variant)
import numpy, tensorflow
(x_train, y_train), (x_test, y_test) = tensorflow.keras.datasets.mnist.load_data()
#x_train.shape=(60000, 28, 28), x_test.shape=(60000, 28, 28)
#y_train.shape=(60000,), y_test.shape=(10000,)
x_train = x_train.reshape(60000, 784).astype("float32") / 255
#x_train.shape=(60000, 784)
x_test = x_test.reshape(10000, 784).astype("float32") / 255
#x_test.shape=(10000, 784)
y_train = tensorflow.keras.utils.to_categorical(y_train)
#y_train.shape=(60000, 10)
y_test = tensorflow.keras.utils.to_categorical(y_test)
#y_test.shape=(60000, 10)
mlp = tensorflow.keras.models.Sequential()
mlp.add(tensorflow.keras.layers.Dense(units=64, input_shape=(784,), activation="relu"))
mlp.add(tensorflow.keras.layers.Dense(units=64, activation="relu"))
mlp.add(tensorflow.keras.layers.Dense(units=10, activation='softmax')) 
mlp.compile(optimizer="RMSprop", loss='categorical_crossentropy', metrics=["accuracy"])
history = mlp.fit(x=x_train, y=y_train, batch_size=64, epochs=2, validation_split=0.2)
test_scores = mlp.evaluate(x=x_test, y=y_test, verbose=2)
print("Test loss:", test_scores[0])
print("Test accuracy:", test_scores[1])
y_model = mlp.predict_classes(x=x_test)
print("y_test[1:10]:", numpy.argmax(y_test[1:10], axis=1))
print("y_model[1:10]:", y_model[1:10])
mlp.summary()
tensorflow.keras.utils.plot_model(mlp, show_shapes=True)

#Classifier image (10 class, image 28x28)
#Create CFNN (first variant)
import numpy, tensorflow
(x_train, y_train), (x_test, y_test) = tensorflow.keras.datasets.mnist.load_data()
#x_train.shape=(60000, 28, 28), x_test.shape=(10000, 28, 28)
#y_train.shape=(60000,), y_test.shape=(10000,)
x_train = x_train.reshape(60000, 784).astype("float32") / 255
#x_train.shape=(60000, 784)
x_test = x_test.reshape(10000, 784).astype("float32") / 255
#x_test.shape=(10000, 784)
y_train = tensorflow.keras.utils.to_categorical(y_train)
#y_train.shape=(60000, 10)
y_test = tensorflow.keras.utils.to_categorical(y_test)
#y_test.shape=(10000, 10)
#5 => (0,0,0,0,1,0,0,0,0,0)
inputs = tensorflow.keras.Input(shape=(784,))
hidden1 = tensorflow.keras.layers.Dense(units=64, activation='relu')(inputs)
inputs_hidden1 = tensorflow.keras.layers.Concatenate()([inputs, hidden1])
hidden2 = tensorflow.keras.layers.Dense(units=64, activation='relu')(inputs_hidden1)
inputs_hidden1_hidden2 = tensorflow.keras.layers.Concatenate()([inputs, hidden1, hidden2])
outputs = tensorflow.keras.layers.Dense(units=10, activation='softmax')(inputs_hidden1_hidden2)
cfnn = tensorflow.keras.Model(inputs=inputs, outputs=outputs, name="mnist_model")
cfnn.compile(optimizer="RMSprop", loss='categorical_crossentropy', metrics=["accuracy"])
history = cfnn.fit(x=x_train, y=y_train, batch_size=64, epochs=2, validation_split=0.2)
test_scores = cfnn.evaluate(x=x_test, y=y_test, verbose=2)
print("Test loss:", test_scores[0])
print("Test accuracy:", test_scores[1])
y_model = cfnn.predict(x=x_test)
print("y_test[1:10]:", numpy.argmax(y_test[1:10], axis=1))
print("y_model[1:10]:", numpy.argmax(y_model[1:10], axis=1))
cfnn.summary()
tensorflow.keras.utils.plot_model(cfnn, show_shapes=True)

